{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae970aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae82a411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hourly_score</th>\n",
       "      <th>hourly_count</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647632</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.404465</td>\n",
       "      <td>17</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.432473</td>\n",
       "      <td>20</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601063</td>\n",
       "      <td>85</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604386</td>\n",
       "      <td>74</td>\n",
       "      <td>2009-04-07 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  sentiment  hourly_score  hourly_count  \\\n",
       "0  2009      4    7     5          1      0.647632            64   \n",
       "1  2009      4    7     5          0     -0.404465            17   \n",
       "2  2009      4    7     6          0     -0.432473            20   \n",
       "3  2009      4    7     6          1      0.601063            85   \n",
       "4  2009      4    7     7          1      0.604386            74   \n",
       "\n",
       "              datetime  \n",
       "0  2009-04-07 05:00:00  \n",
       "1  2009-04-07 05:00:00  \n",
       "2  2009-04-07 06:00:00  \n",
       "3  2009-04-07 06:00:00  \n",
       "4  2009-04-07 07:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_hour_pd = pd.read_csv('tweets_hour.csv')\n",
    "tweets_hour_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3b0c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1177 entries, 0 to 1176\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   year          1177 non-null   int64  \n",
      " 1   month         1177 non-null   int64  \n",
      " 2   day           1177 non-null   int64  \n",
      " 3   hour          1177 non-null   int64  \n",
      " 4   sentiment     1177 non-null   int64  \n",
      " 5   hourly_score  1177 non-null   float64\n",
      " 6   hourly_count  1177 non-null   int64  \n",
      " 7   datetime      1177 non-null   object \n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 73.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_hour_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6763ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hourly_score</th>\n",
       "      <th>hourly_count</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, month, day, hour, sentiment, hourly_score, hourly_count, datetime]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_hour_pd = tweets_hour_pd.drop_duplicates(subset=['datetime','sentiment'])\n",
    "print(len(tweets_hour_pd))\n",
    "tweets_hour_pd[tweets_hour_pd.datetime == '2009-04-07 01:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047cd704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# transformers and preprocessing\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "# models\n",
    "#from darts.models import NaiveSeasonal, StatsForecastAutoARIMA, ExponentialSmoothing, Prophet #local\n",
    "#from darts.models import LightGBMModel, RNNModel, NBEATSModel, TFTModel #global\n",
    "\n",
    "# likelihood\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "# evaluation\n",
    "from darts.metrics import mape, coefficient_of_variation, mae \n",
    "\n",
    "# settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207a9beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hourly_score</th>\n",
       "      <th>hourly_count</th>\n",
       "      <th>datetime</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>hour_scaled</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.647632</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>278</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.404465</td>\n",
       "      <td>17</td>\n",
       "      <td>2009-04-07 05:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.432473</td>\n",
       "      <td>20</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601063</td>\n",
       "      <td>85</td>\n",
       "      <td>2009-04-07 06:00:00</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604386</td>\n",
       "      <td>74</td>\n",
       "      <td>2009-04-07 07:00:00</td>\n",
       "      <td>34</td>\n",
       "      <td>230</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.374728</td>\n",
       "      <td>15</td>\n",
       "      <td>2009-04-07 07:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>63</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.354589</td>\n",
       "      <td>21</td>\n",
       "      <td>2009-04-07 08:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613716</td>\n",
       "      <td>65</td>\n",
       "      <td>2009-04-07 08:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>200</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>72</td>\n",
       "      <td>2009-04-07 09:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>193</td>\n",
       "      <td>0.284024</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.401946</td>\n",
       "      <td>6</td>\n",
       "      <td>2009-04-07 09:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  sentiment  hourly_score  hourly_count  \\\n",
       "0  2009      4    7     5          1      0.647632            64   \n",
       "1  2009      4    7     5          0     -0.404465            17   \n",
       "2  2009      4    7     6          0     -0.432473            20   \n",
       "3  2009      4    7     6          1      0.601063            85   \n",
       "4  2009      4    7     7          1      0.604386            74   \n",
       "5  2009      4    7     7          0     -0.374728            15   \n",
       "6  2009      4    7     8          0     -0.354589            21   \n",
       "7  2009      4    7     8          1      0.613716            65   \n",
       "8  2009      4    7     9          1      0.600345            72   \n",
       "9  2009      4    7     9          0     -0.401946             6   \n",
       "\n",
       "             datetime  min_hour  max_hour  hour_scaled day_of_week  \n",
       "0 2009-04-07 05:00:00         8       278     0.207407     Tuesday  \n",
       "1 2009-04-07 05:00:00         3        54     0.274510     Tuesday  \n",
       "2 2009-04-07 06:00:00        10        59     0.204082     Tuesday  \n",
       "3 2009-04-07 06:00:00        44       249     0.200000     Tuesday  \n",
       "4 2009-04-07 07:00:00        34       230     0.204082     Tuesday  \n",
       "5 2009-04-07 07:00:00        11        63     0.076923     Tuesday  \n",
       "6 2009-04-07 08:00:00        14        47     0.212121     Tuesday  \n",
       "7 2009-04-07 08:00:00        26       200     0.224138     Tuesday  \n",
       "8 2009-04-07 09:00:00        24       193     0.284024     Tuesday  \n",
       "9 2009-04-07 09:00:00         6        50     0.000000     Tuesday  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make copy of df\n",
    "dataset_scaled_EDA = tweets_hour_pd.copy()\n",
    "\n",
    "# min max value calculation\n",
    "dataset_scaled_EDA['min_hour'] = dataset_scaled_EDA.groupby(['hour','sentiment'])[['hourly_count']] \\\n",
    "                                    .transform(lambda x: x.min())\n",
    "dataset_scaled_EDA['max_hour'] = dataset_scaled_EDA.groupby(['hour','sentiment'])[['hourly_count']] \\\n",
    "                                    .transform(lambda x: x.max())\n",
    "\n",
    "# scale\n",
    "dataset_scaled_EDA['hour_scaled'] = (dataset_scaled_EDA['hourly_count'] - dataset_scaled_EDA['min_hour'])/(dataset_scaled_EDA['max_hour'] - dataset_scaled_EDA['min_hour'])\n",
    "\n",
    "# add info about year, week of year and day of week\n",
    "dataset_scaled_EDA['datetime'] = pd.to_datetime(dataset_scaled_EDA['datetime'])\n",
    "dataset_scaled_EDA['day_of_week'] = [d.strftime('%A') for d in dataset_scaled_EDA['datetime']]\n",
    "dataset_scaled_EDA['day_of_week'] = pd.Categorical(dataset_scaled_EDA['day_of_week'], \n",
    "  categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], \n",
    "  ordered=True)\n",
    "\n",
    "dataset_scaled_EDA.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d3e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_df_sent(df_send, sent=False, target_col='hourly_count', rename_target_col='target', new_index=False,\n",
    "                split_col='datetime', split_date='2009-04-01', freq_timestamp='H', x_col=[]):\n",
    "\n",
    "    df = df_send.copy()\n",
    "    \n",
    "    n_row = len(df)\n",
    "\n",
    "    if not sent == False:\n",
    "        sent_desc = 'Positive' if sent == '1' else 'Negative'\n",
    "        print(f'Dataframe Sentiment: {sent_desc}')\n",
    "\n",
    "        # Remove Sentiment:\n",
    "        df = df[df.sentiment == sent]\n",
    "        n_row = len(df)\n",
    "\n",
    "    print(f'Total Number of rows: {n_row}')\n",
    "    cols = x_col\n",
    "\n",
    "    if not new_index == False:\n",
    "        # Apply Time as index\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        df = df.set_index('datetime')\n",
    "\n",
    "        # verifying if there are missing time (hour)\n",
    "        df = df.asfreq(freq_timestamp)\n",
    "        print(f\"NA's rows Number: {np.abs(n_row - len(df))}\")\n",
    "        df = df.fillna(0)\n",
    "\n",
    "    df = df.rename(columns={target_col: rename_target_col})\n",
    "    cols.append(rename_target_col)\n",
    "    \n",
    "    if new_index == False:\n",
    "        cols.append(split_col)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    # Splitting dataframes into train-test\n",
    "    if new_index == False:\n",
    "        df_train = df[pd.to_datetime(df[split_col], format='%Y-%m-%d %H:%M:%S') < pd.to_datetime(split_date, format='%Y-%m-%d')]\n",
    "        print(f\"Train dates : {df_train[split_col].min()} --- {df_train[split_col].max()}  (n={len(df_train)} -> {len(df_train)/len(df):.2%})\")\n",
    "\n",
    "        df_test = df[pd.to_datetime(df[split_col], format='%Y-%m-%d %H:%M:%S') >= pd.to_datetime(split_date, format='%Y-%m-%d')]\n",
    "        print(f\"Test dates  : {df_test[split_col].min()} --- {df_test[split_col].max()}  (n={len(df_test)} -> {len(df_test)/len(df):.2%})\")\n",
    "\n",
    "    else:\n",
    "        df_train = df.loc[df.index < pd.to_datetime(split_date, format='%Y-%m-%d')]\n",
    "        print(f\"Train dates : {df_train.index.min()} --- {df_train.index.max()}  (n={len(df_train)} -> {len(df_train)/len(df):.2%})\")\n",
    "\n",
    "        df_test = df.loc[df.index >= pd.to_datetime(split_date, format='%Y-%m-%d')]\n",
    "        print(f\"Test dates  : {df_test.index.min()} --- {df_test.index.max()}  (n={len(df_test)} -> {len(df_test)/len(df):.2%})\")\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 4))\n",
    "    df_train[rename_target_col].plot(ax=ax, label='train', color='blue')\n",
    "    df_test[rename_target_col].plot(ax=ax, label='test', color='black')\n",
    "    ax.legend();\n",
    "    ax.set_title(f\"Train-Test dataframes {sent_desc} Sentiment\")\n",
    "\n",
    "    return df, df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a78528",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ts = tweets_hour_pd.copy()\n",
    "dataset_ts = TimeSeries.from_group_dataframe(df=dataset_ts,\n",
    "                                             group_cols= 'sentiment',\n",
    "                                             time_col='datetime',\n",
    "                                             value_cols='hourly_count',\n",
    "                                             freq= 'H',\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e3562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 333.40it/s]\n"
     ]
    }
   ],
   "source": [
    "first_test_date = pd.Timestamp('2009-04-08')\n",
    "train_dataset_ts, test_dataset_ts = [], []\n",
    "\n",
    "for single_ts in tqdm(dataset_ts):\n",
    "    # split into train and test tests\n",
    "    single_train_ts, single_test_ts = single_ts.split_before(first_test_date)\n",
    "    train_dataset_ts.append(single_train_ts)\n",
    "    test_dataset_ts.append(single_test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98bcf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizons = len(test_dataset_ts[0])\n",
    "\n",
    "def _backtests_local_estimator(_estimator, _ts_set, _split_date, _horizons, _single_forecast):\n",
    "    model = _estimator\n",
    "    if _single_forecast:\n",
    "        model.fit(_ts_set.split_before(_split_date)[0])\n",
    "        backtests_single_ts = model.predict(_horizons)\n",
    "    \n",
    "    else:\n",
    "        backtests_single_ts = model.historical_forecasts(series=_ts_set, \n",
    "                                                         start=_split_date - np.timedelta64(_horizons-1, 'D'), \n",
    "                                                         verbose=False, \n",
    "                                                         overlap_end=False,\n",
    "                                                         last_points_only=True, \n",
    "                                                         forecast_horizon=_horizons,\n",
    "                                                         retrain=True)\n",
    "    \n",
    "    return backtests_single_ts\n",
    "\n",
    "def backtests_multiple_local_estimators(estimator, multiple_ts_sets=dataset_ts, split_date=first_test_date, horizons=forecast_horizons, single_forecast=True):\n",
    "    backtests_multiple_ts = Parallel(n_jobs=-1,\n",
    "                                     verbose=5, \n",
    "                                     backend = 'multiprocessing',\n",
    "                                     pre_dispatch='1.5*n_jobs')(\n",
    "            delayed(_backtests_local_estimator)(\n",
    "                _estimator=estimator,\n",
    "                _ts_set=single_ts_set,\n",
    "                _split_date=split_date,\n",
    "                _horizons=horizons,\n",
    "                _single_forecast=single_forecast\n",
    "            )\n",
    "        for single_ts_set in multiple_ts_sets\n",
    "    )\n",
    "    \n",
    "    return backtests_multiple_ts\n",
    "\n",
    "\n",
    "def darts_kpi(prediction_series, test_series=test_dataset_ts):\n",
    "    mape_ = np.round(np.mean(mape(actual_series=test_series, \n",
    "                                 pred_series=prediction_series, n_jobs=-1)),\n",
    "                    2)\n",
    "    print(f' MAPE: {mape_}')\n",
    "    \n",
    "    rmse_ = np.round(np.mean(coefficient_of_variation(actual_series=test_series, \n",
    "                                 pred_series=prediction_series, n_jobs=-1)),\n",
    "                    2)\n",
    "    print(f' RMSE: {rmse_}')\n",
    "    \n",
    "    mae_ = np.round(np.mean(mae(actual_series=test_series, \n",
    "                                 pred_series=prediction_series, n_jobs=-1)),\n",
    "                    2)\n",
    "    print(f' MAE: {mae_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0468eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import NaiveSeasonal\n",
    "\n",
    "backtests_baseline_model = backtests_multiple_local_estimators(estimator=NaiveSeasonal(K=365))\n",
    "darts_kpi(backtests_baseline_model)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "test_dataset_ts[0].plot(label='True value', color='black')\n",
    "backtests_baseline_model[0].plot(label='Forecast', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa55c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from darts.models import Croston\n",
    "\n",
    "backtests_croston = backtests_multiple_local_estimators(estimator=Croston())\n",
    "darts_kpi(backtests_croston)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "test_dataset_ts[0].plot(label='True value', color='black')\n",
    "backtests_croston[0].plot(label='Forecast', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtests_AUTOarima = backtests_multiple_local_estimators(estimator=StatsForecastAutoARIMA())\n",
    "darts_kpi(backtests_AUTOarima)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "test_dataset_ts[0].plot(label='True value', color='black')\n",
    "backtests_AUTOarima[0].plot(label='Forecast', color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffd0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c0915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
