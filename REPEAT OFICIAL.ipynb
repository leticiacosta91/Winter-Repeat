{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2a711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIE\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d55439",
   "metadata": {},
   "source": [
    "# DATA FRAME ORIGINAL - Project Tweets - Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e233e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_   \n",
       "0  1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton  \\\n",
       "1  2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  5  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ProjectTweets.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad0915",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fc1bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e6ceb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                       int64\n",
       "1467810369                                                                                                              int64\n",
       "Mon Apr 06 22:19:45 PDT 2009                                                                                           object\n",
       "NO_QUERY                                                                                                               object\n",
       "_TheSpecialOne_                                                                                                        object\n",
       "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9083dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                                                                                               Non-Null Count    Dtype \n",
      "---  ------                                                                                                               --------------    ----- \n",
      " 0   0                                                                                                                    1599999 non-null  int64 \n",
      " 1   1467810369                                                                                                           1599999 non-null  int64 \n",
      " 2   Mon Apr 06 22:19:45 PDT 2009                                                                                         1599999 non-null  object\n",
      " 3   NO_QUERY                                                                                                             1599999 non-null  object\n",
      " 4   _TheSpecialOne_                                                                                                      1599999 non-null  object\n",
      " 5   @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c71c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                      0\n",
       "1467810369                                                                                                             0\n",
       "Mon Apr 06 22:19:45 PDT 2009                                                                                           0\n",
       "NO_QUERY                                                                                                               0\n",
       "_TheSpecialOne_                                                                                                        0\n",
       "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd5b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[-1] = df.columns\n",
    "df.index = df.index + 1\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139f5432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_  \\\n",
       "1  1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...                                                                   \n",
       "1  is upset that he can't update his Facebook by ...                                                                   \n",
       "2  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "3    my whole body feels itchy and like its on fire                                                                    \n",
       "4  @nationwideclass no, it's not behaving at all....                                                                   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0d8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [\"Index\", \"ID\", \"Date/Time\", \"Info\", \"User\", \"Tweet\"]\n",
    "df.columns = new_columns\n",
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d670cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Info</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index          ID                     Date/Time      Info             User   \n",
       "0     0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_  \\\n",
       "1     1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2     2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "\n",
       "                                               Tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1bfaeb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "018951d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['H1N1', 'Swine flu', 'Influenza A', 'Pandemic flu', 'Flu outbreak', \n",
    "            'H1N1 symptoms', 'H1N1 transmission', 'H1N1 vaccine', 'Antiviral medications', \n",
    "            'International health emergency', 'Swine Origin Influenza', 'Influenza Vaccine', \n",
    "            'Influenza Transmission', 'Influenza Treatment', 'Flu Virus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e319b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df1[\"Tweet\"].str.contains('|'.join(keywords), case=False)\n",
    "df2 = tweets_fil = df1[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b63aff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Info</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41612</th>\n",
       "      <td>41612</td>\n",
       "      <td>1675708738</td>\n",
       "      <td>Fri May 01 20:08:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>junoaggy</td>\n",
       "      <td>swine flu attacks HK so i can't go  screw you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>41641</td>\n",
       "      <td>1675712950</td>\n",
       "      <td>Fri May 01 20:09:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JasJazzy</td>\n",
       "      <td>Swine Flu  Why oh why did you come to canada????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>41642</td>\n",
       "      <td>1675713013</td>\n",
       "      <td>Fri May 01 20:09:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>fireflyjane</td>\n",
       "      <td>is congested, feverish and aches...hope I didn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41878</th>\n",
       "      <td>41878</td>\n",
       "      <td>1675828003</td>\n",
       "      <td>Fri May 01 20:25:32 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rach107</td>\n",
       "      <td>swine flu at jwu   hiding outt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42072</th>\n",
       "      <td>42072</td>\n",
       "      <td>1675929811</td>\n",
       "      <td>Fri May 01 20:40:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lonewolfmedia</td>\n",
       "      <td>They cancelled the First Monday flea market he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index          ID                     Date/Time      Info   \n",
       "41612  41612  1675708738  Fri May 01 20:08:51 PDT 2009  NO_QUERY  \\\n",
       "41641  41641  1675712950  Fri May 01 20:09:26 PDT 2009  NO_QUERY   \n",
       "41642  41642  1675713013  Fri May 01 20:09:27 PDT 2009  NO_QUERY   \n",
       "41878  41878  1675828003  Fri May 01 20:25:32 PDT 2009  NO_QUERY   \n",
       "42072  42072  1675929811  Fri May 01 20:40:13 PDT 2009  NO_QUERY   \n",
       "\n",
       "                User                                              Tweet  \n",
       "41612       junoaggy  swine flu attacks HK so i can't go  screw you ...  \n",
       "41641       JasJazzy   Swine Flu  Why oh why did you come to canada????  \n",
       "41642    fireflyjane  is congested, feverish and aches...hope I didn...  \n",
       "41878        rach107                     swine flu at jwu   hiding outt  \n",
       "42072  lonewolfmedia  They cancelled the First Monday flea market he...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6126be1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1402, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ff2633e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1402 entries, 41612 to 1599128\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Index      1402 non-null   object\n",
      " 1   ID         1402 non-null   object\n",
      " 2   Date/Time  1402 non-null   object\n",
      " 3   Info       1402 non-null   object\n",
      " 4   User       1402 non-null   object\n",
      " 5   Tweet      1402 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c78d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_parquet(\"/home/hduser/Desktop/TWEETS_H1N1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51102677",
   "metadata": {},
   "source": [
    "# Tratamento de dados (FIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32c64083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:19:47 WARN Utils: Your hostname, BDS-2023 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/12/31 00:19:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/31 00:19:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/31 00:19:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark_conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Tweets_Hadoop\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).config('spark.sql.session.timeZone', 'UTC').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setLogLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fac4ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_spark = spark.read.parquet(\"hdfs://localhost:9000/CA4/TWETTS_H1N1.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41acbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: long (nullable = true)\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Date/Time: string (nullable = true)\n",
      " |-- Info: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- Tweet: string (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "871aa8d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------------------+--------+-----------+--------------------+-----------------+\n",
      "|summary|            Index|                  ID|           Date/Time|    Info|       User|               Tweet|__index_level_0__|\n",
      "+-------+-----------------+--------------------+--------------------+--------+-----------+--------------------+-----------------+\n",
      "|  count|             1402|                1402|                1402|    1402|       1402|                1402|             1402|\n",
      "|   mean|578804.5085592011|2.0001463479579172E9|                null|    null|       null|                null|578804.5085592011|\n",
      "| stddev|401653.7588381154|2.1242077954807264E8|                null|    null|       null|                null|401653.7588381154|\n",
      "|    min|            41612|          1675708738|Fri Jun 05 08:44:...|NO_QUERY|  13zneralc| I feel a cold co...|            41612|\n",
      "|    25%|           254826|          1824446054|                null|    null|       null|                null|           254826|\n",
      "|    50%|           540128|          2014624646|                null|    null|       null|                null|           540128|\n",
      "|    75%|           859907|          2198205344|                null|    null|       null|                null|           859907|\n",
      "|    max|          1599128|          2328821749|Wed Jun 24 23:35:...|NO_QUERY|zombiesheep|yup, def swine fl...|          1599128|\n",
      "+-------+-----------------+--------------------+--------------------+--------+-----------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_spark.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ec61f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "spark = spark.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fdb30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_spark = tweets_spark.withColumn(\"Date/Time\", to_timestamp(tweets_spark[\"Date/Time\"], \"EEE MMM dd HH:mm:ss zzz yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "783b79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_spark = tweets_spark.select(\"ID\", \"Date/Time\", \"User\", \"Tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b43c4850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------+--------------------+\n",
      "|        ID|          Date/Time|         User|               Tweet|\n",
      "+----------+-------------------+-------------+--------------------+\n",
      "|1675708738|2009-05-02 03:08:51|     junoaggy|swine flu attacks...|\n",
      "|1675712950|2009-05-02 03:09:26|     JasJazzy|Swine Flu  Why oh...|\n",
      "|1675713013|2009-05-02 03:09:27|  fireflyjane|is congested, fev...|\n",
      "|1675828003|2009-05-02 03:25:32|      rach107|swine flu at jwu ...|\n",
      "|1675929811|2009-05-02 03:40:13|lonewolfmedia|They cancelled th...|\n",
      "+----------+-------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:===========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_spark.show(truncate=True, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3af190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Date/Time: timestamp (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- Tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a693e394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Date/Time: timestamp (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- Tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46b252b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, count, format_string, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f121cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----------+\n",
      "|year|month|count|percentage|\n",
      "+----+-----+-----+----------+\n",
      "|2009|5    |569  |40.58%    |\n",
      "|2009|6    |833  |59.42%    |\n",
      "+----+-----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verifique a distribuição de tweets por mês\n",
    "df = tweets_spark.groupBy(year(\"Date/Time\").alias(\"year\"), month(\"Date/Time\").alias(\"month\")).count() \\\n",
    "                 .orderBy([\"year\", \"month\"])\n",
    "\n",
    "# Obtenha a porcentagem\n",
    "df = df.withColumn(\"percentage\", format_string(\"%.2f%%\", ((col(\"count\")/tweets_spark.count())*100)))\n",
    "\n",
    "# Mostre o DataFrame resultante\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39e263ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91a20fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+---------------------------------+\n",
      "|ItemID|Sentiment|SentimentSource|SentimentText                    |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "|1038  |1        |Sentiment140   |that film is fantastic #brilliant|\n",
      "|1804  |1        |Sentiment140   |this music is really bad #myband |\n",
      "|1693  |0        |Sentiment140   |winter is terrible #thumbs-down  |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read csv file into dataFrame with automatically inferred schema\n",
    "tweets_csv = spark.read.csv(\"hdfs://localhost:9000/CA4/tweets.csv\", inferSchema=True, header=True)\n",
    "tweets_csv.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8766d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|SentimentText                    |label|\n",
      "+---------------------------------+-----+\n",
      "|that film is fantastic #brilliant|1    |\n",
      "|this music is really bad #myband |1    |\n",
      "|winter is terrible #thumbs-down  |0    |\n",
      "|this game is awful #nightmare    |0    |\n",
      "|I love jam #loveit               |1    |\n",
      "+---------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select only \"SentimentText\" and \"Sentiment\" column, \n",
    "#and cast \"Sentiment\" column data into integer\n",
    "data = tweets_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = False,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a7bf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 1405 ; Testing data rows: 527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#divide data, 70% for training, 30% for testing\n",
    "dividedData = data.randomSplit([0.7, 0.3]) \n",
    "trainingData = dividedData[0] #index 0 = data training\n",
    "testingData = dividedData[1] #index 1 = data testing\n",
    "train_rows = trainingData.count()\n",
    "test_rows = testingData.count()\n",
    "print (\"Training data rows:\", train_rows, \"; Testing data rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da335a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+\n",
      "|SentimentText            |label|SentimentWords                |\n",
      "+-------------------------+-----+------------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |\n",
      "|I adore cheese #brilliant|1    |[i, adore, cheese, #brilliant]|\n",
      "|I adore cheese #favorite |1    |[i, adore, cheese, #favorite] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |\n",
      "|I adore cheese #thumbs-up|1    |[i, adore, cheese, #thumbs-up]|\n",
      "+-------------------------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
    "tokenizedTrain = tokenizer.transform(trainingData)\n",
    "tokenizedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5432c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|SentimentText            |label|SentimentWords                |MeaningfulWords            |\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |[adore, cheese, #bestever] |\n",
      "|I adore cheese #brilliant|1    |[i, adore, cheese, #brilliant]|[adore, cheese, #brilliant]|\n",
      "|I adore cheese #favorite |1    |[i, adore, cheese, #favorite] |[adore, cheese, #favorite] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |[adore, cheese, #loveit]   |\n",
      "|I adore cheese #thumbs-up|1    |[i, adore, cheese, #thumbs-up]|[adore, cheese, #thumbs-up]|\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b709be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[1689,91011,100089],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[1689,45361,100089],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #favorite] |(262144,[1689,100089,108624],[1.0,1.0,1.0])|\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
    "    'label', 'MeaningfulWords', 'features')\n",
    "numericTrainData.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc1e5392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print (\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9da42bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 36:>                                                         (0 + 1) / 1]\r",
      "\r",
      "[Stage 36:==========================================================(1 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+-------------------------------------------------------+\n",
      "|Label|MeaningfulWords                      |features                                               |\n",
      "+-----+-------------------------------------+-------------------------------------------------------+\n",
      "|1    |[adore, classical, music, #thumbs-up]|(262144,[88825,100089,102383,131250],[1.0,1.0,1.0,1.0])|\n",
      "|1    |[adore, coffee, #loveit]             |(262144,[100089,159212,254974],[1.0,1.0,1.0])          |\n",
      "+-----+-------------------------------------+-------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select(\n",
    "    'Label', 'MeaningfulWords', 'features')\n",
    "numericTest.show(truncate=False, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "996f50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+----------+-----+\n",
      "|MeaningfulWords                      |prediction|Label|\n",
      "+-------------------------------------+----------+-----+\n",
      "|[adore, classical, music, #thumbs-up]|1.0       |1    |\n",
      "|[adore, coffee, #loveit]             |1.0       |1    |\n",
      "|[adore, jam, #loveit]                |1.0       |1    |\n",
      "|[adore, jam, #toptastic]             |1.0       |1    |\n",
      "+-------------------------------------+----------+-----+\n",
      "only showing top 4 rows\n",
      "\n",
      "correct prediction: 520 , total data: 527 , accuracy: 0.9867172675521821\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
    "predictionFinal.show(n=4, truncate = False)\n",
    "correctPrediction = predictionFinal.filter(\n",
    "    predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "totalData = predictionFinal.count()\n",
    "print(\"correct prediction:\", correctPrediction, \", total data:\", totalData, \n",
    "      \", accuracy:\", correctPrediction/totalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3560f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb3ac495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de expressões regulares\n",
    "at_regex = r\"@\\w+\"  # Remove usernames\n",
    "link_regex = r\"http\\S+\"  # Remove links\n",
    "rt_regex = r'\\bRT\\b'  # Remove 'RT'\n",
    "ss_regex = r'[^\\w\\s]'  # Remove Special strings\n",
    "ds_regex = r'\\s+'  # Remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64a5b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ID        |Date/Time          |User         |Tweet                                                                                                                                          |clean_tweet                                                                                                                     |\n",
      "+----------+-------------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1675708738|2009-05-02 03:08:51|junoaggy     |swine flu attacks HK so i can't go  screw you swines!                                                                                          |swine flu attacks HK so i cant go screw you swines                                                                              |\n",
      "|1675712950|2009-05-02 03:09:26|JasJazzy     |Swine Flu  Why oh why did you come to canada????                                                                                               |Swine Flu Why oh why did you come to canada                                                                                     |\n",
      "|1675713013|2009-05-02 03:09:27|fireflyjane  |is congested, feverish and aches...hope I didnt catch the SWINE FLU                                                                            |is congested feverish and acheshope I didnt catch the SWINE FLU                                                                 |\n",
      "|1675828003|2009-05-02 03:25:32|rach107      |swine flu at jwu   hiding outt                                                                                                                 |swine flu at jwu hiding outt                                                                                                    |\n",
      "|1675929811|2009-05-02 03:40:13|lonewolfmedia|They cancelled the First Monday flea market here where I live due to &quot;swine flu!&quot;    I was gonna go!!! INSANITY INSANITY INSANITY!!!!|They cancelled the First Monday flea market here where I live due to quotswine fluquot I was gonna go INSANITY INSANITY INSANITY|\n",
      "+----------+-------------------+-------------+-----------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_spark = tweets_spark.withColumn(\"clean_tweet\", regexp_replace(\"Tweet\", at_regex, \"\"))\n",
    "tweets_spark = tweets_spark.withColumn(\"clean_tweet\", regexp_replace(\"clean_tweet\", link_regex, \"\"))\n",
    "tweets_spark = tweets_spark.withColumn(\"clean_tweet\", regexp_replace(\"clean_tweet\", rt_regex, \"\"))\n",
    "tweets_spark = tweets_spark.withColumn(\"clean_tweet\", regexp_replace(\"clean_tweet\", ss_regex, \"\"))\n",
    "tweets_spark = tweets_spark.withColumn(\"clean_tweet\", regexp_replace(\"clean_tweet\", ds_regex, \" \"))\n",
    "\n",
    "# Exibição dos resultados\n",
    "tweets_spark.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d84a3692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|     MeaningfulWords|            features|\n",
      "+--------------------+--------------------+\n",
      "|[swine, flu, atta...|(262144,[40873,61...|\n",
      "|[swine, flu, oh, ...|(262144,[18184,16...|\n",
      "|[congested, fever...|(262144,[46168,71...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"clean_tweet\", outputCol=\"words\")\n",
    "tokenizedData = tokenizer.transform(tweets_spark)\n",
    "\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemoved = swr.transform(tokenizedData)\n",
    "\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericData = hashTF.transform(SwRemoved).select('MeaningfulWords', 'features')\n",
    "\n",
    "\n",
    "numericData.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d359326",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(numericData)\n",
    "\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75cab8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------+----------+\n",
      "|MeaningfulWords                                                                                                 |prediction|\n",
      "+----------------------------------------------------------------------------------------------------------------+----------+\n",
      "|[swine, flu, attacks, hk, cant, go, screw, swines]                                                              |0.0       |\n",
      "|[swine, flu, oh, come, canada]                                                                                  |0.0       |\n",
      "|[congested, feverish, acheshope, didnt, catch, swine, flu]                                                      |0.0       |\n",
      "|[swine, flu, jwu, hiding, outt]                                                                                 |0.0       |\n",
      "|[cancelled, first, monday, flea, market, live, due, quotswine, fluquot, gonna, go, insanity, insanity, insanity]|0.0       |\n",
      "|[sickishnot, swine, flu, tho, promisejust, bad, piece, pizza, thoughtsbut, tasted, o, good]                     |1.0       |\n",
      "|[, yay, elbow, hifives, swine, flu, got, little, scared]                                                        |0.0       |\n",
      "|[im, getting, pretty, tired, hearing, swine, flu, swineflu]                                                     |0.0       |\n",
      "|[, aw, poor, nikki, im, bad, im, ready, ova, u, sure, u, dont, swine, flu, lol, playin]                         |0.0       |\n",
      "|[heard, news, end, year, well, get, swine, flu, even, vegetarians, government, evil]                            |0.0       |\n",
      "+----------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictionFinal.show(truncate = False, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b5edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1402"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionFinal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25638f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+--------------------+--------------------+----------+\n",
      "|          Date/Time|           User|               tweet|         clean_tweet|prediction|\n",
      "+-------------------+---------------+--------------------+--------------------+----------+\n",
      "|2009-05-02 03:08:51|       junoaggy|swine flu attacks...|swine flu attacks...|       0.0|\n",
      "|2009-05-02 03:09:26|       JasJazzy|Swine Flu  Why oh...|Swine Flu Why oh ...|       0.0|\n",
      "|2009-05-02 03:09:27|    fireflyjane|is congested, fev...|is congested feve...|       0.0|\n",
      "|2009-05-02 03:25:32|        rach107|swine flu at jwu ...|swine flu at jwu ...|       0.0|\n",
      "|2009-05-02 03:40:13|  lonewolfmedia|They cancelled th...|They cancelled th...|       0.0|\n",
      "|2009-05-02 03:45:31|JasperDracoLuvr|is sick-ish...not...|is sickishnot swi...|       1.0|\n",
      "|2009-05-02 03:49:48|   LauraRepetti|@ddlovato Yay for...| Yay for elbow hi...|       0.0|\n",
      "|2009-05-02 04:14:17|       pennz0il|I'm getting prett...|Im getting pretty...|       0.0|\n",
      "|2009-05-02 04:23:44|        Nayboo1|@nikkiham1982 Aw ...| Aw poor Nikki Im...|       0.0|\n",
      "|2009-05-02 04:23:54|    AttentionHo|I just heard on t...|I just heard on t...|       0.0|\n",
      "|2009-05-02 04:25:48|    ryanmcgrath|So after sleeping...|So after sleeping...|       0.0|\n",
      "|2009-05-02 04:28:53| countrycitygal|if swine flu cont...|if swine flu cont...|       0.0|\n",
      "|2009-05-02 04:49:57|      TylerFish|Yeah! Only three ...|Yeah Only three m...|       0.0|\n",
      "|2009-05-02 04:56:10|   karebear1212|i think guys thin...|i think guys thin...|       1.0|\n",
      "|2009-05-02 05:30:48|    beijingbaby|Swine flu in Chin...|Swine flu in Chin...|       0.0|\n",
      "|2009-05-02 05:48:57|       weiwitch|swine flu in HK. ...|swine flu in HK g...|       0.0|\n",
      "|2009-05-02 06:04:55|      janine_j9|@bazanna r u talk...| r u talking abou...|       0.0|\n",
      "|2009-05-02 06:20:28|     alilovesya|Going home sick  ...|Going home sick t...|       0.0|\n",
      "|2009-05-02 06:28:55|         fweaky|im alive!! i have...|im alive i have y...|       0.0|\n",
      "|2009-05-02 06:29:03|ChickenwingsRus|this sucks. i am ...|this sucks i am g...|       0.0|\n",
      "+-------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a column with id following the data's order \n",
    "tweets_spark = tweets_spark.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "predictionFinal = predictionFinal.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# join by \"row_id\"\n",
    "tweets_pred = tweets_spark.select('row_id','Date/Time','User', 'tweet', 'clean_tweet') \\\n",
    "                    .join(predictionFinal.select('row_id', 'prediction'), \"row_id\", \"inner\")\n",
    "                \n",
    "\n",
    "# drop column \n",
    "tweets_pred = tweets_pred.drop(\"row_id\")\n",
    "\n",
    "tweets_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b0ab850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /home/hduser/.local/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/hduser/.local/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: joblib in /home/hduser/.local/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/hduser/.local/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hduser/.local/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2023.12.25)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>=3.1->textblob) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b504a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/hduser/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0365245b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61dca140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hduser/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fb9ae75",
   "metadata": {},
   "source": [
    "#Functions\n",
    "def f_textblob(Tweet):\n",
    "    return TextBlob(Tweet).sentiment.polarity\n",
    "\n",
    "def f_vader(Tweet):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(Tweet)['compound']\n",
    "\n",
    "\n",
    "#UDFs\n",
    "udf_textblob = udf(f_textblob, StringType())\n",
    "\n",
    "udf_vader = udf(f_vader, StringType())\n",
    "\n",
    "\n",
    "#applying to Dataframe\n",
    "tweets_pred = tweets_pred.withColumn(\"textblob\", udf_textblob(tweets_pred[\"clean_tweet\"])) \\\n",
    "                         .withColumn(\"vader\", udf_vader(tweets_pred[\"clean_tweet\"]))\n",
    "\n",
    "#tweets_pred_2.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21deaa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Função de análise de sentimento com TextBlob\n",
    "@udf(FloatType())\n",
    "def sentiment(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "# Função de análise de sentimento com VADER\n",
    "@udf(FloatType())\n",
    "def sentiment_vader(tweet):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(tweet)['compound']\n",
    "\n",
    "# Aplicar diretamente no DataFrame\n",
    "tweets_pred = tweets_pred.withColumn(\"textblob\", sentiment(tweets_pred[\"clean_tweet\"])) \\\n",
    "                         .withColumn(\"vader\", sentiment_vader(tweets_pred[\"clean_tweet\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de21f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pred = tweets_pred.withColumn(\"score\", ((col(\"prediction\") + (col(\"textblob\")*1.5) + (col(\"vader\")*1.5)) / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f887f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------+-------+--------------------+\n",
      "|         clean_tweet|prediction|    textblob|  vader|               score|\n",
      "+--------------------+----------+------------+-------+--------------------+\n",
      "|swine flu attacks...|       0.0|         0.0|-0.6047|-0.22676251083612442|\n",
      "|Swine Flu Why oh ...|       0.0|         0.0|-0.3818|-0.14317499846220016|\n",
      "|is congested feve...|       0.0|        -0.1| -0.516| -0.2309999903663993|\n",
      "|swine flu at jwu ...|       0.0|         0.0|-0.5859| -0.2197125032544136|\n",
      "|They cancelled th...|       0.0|  0.08712121| -0.946|-0.32207953836768866|\n",
      "|is sickishnot swi...|       1.0|5.551115E-17| -0.331| 0.12587499991059303|\n",
      "| Yay for elbow hi...|       0.0|     -0.1875| -0.204|-0.14681249856948853|\n",
      "|Im getting pretty...|       0.0|      -0.075|-0.3182|-0.14744999818503857|\n",
      "| Aw poor Nikki Im...|       0.0|        0.08| 0.7488| 0.31079999171197414|\n",
      "|I just heard on t...|       0.0|        -1.0|-0.7096| -0.6410999894142151|\n",
      "+--------------------+----------+------------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_pred.select(\"clean_tweet\", \"prediction\", \"textblob\", \"vader\", \"score\").show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06cc5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date/Time: timestamp (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- clean_tweet: string (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- textblob: float (nullable = true)\n",
      " |-- vader: float (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_pred.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8a743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from hdfs import InsecureClient\n",
    "from hdfs.util import HdfsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a8f63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colocando no Hadoop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em hdfs://localhost:9000/CA4/sentiment particionado por Date/Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from hdfs import InsecureClient\n",
    "from hdfs.util import HdfsError\n",
    "\n",
    "def spark_hadoop(df, folder, partitionBy=None, spark=None):\n",
    "    hdfs_base_path = \"hdfs://localhost:9000\"\n",
    "    hdfs_folder_path = f\"{hdfs_base_path}/CA4/{folder}\"\n",
    "\n",
    "    client = InsecureClient('http://localhost:9870', user='hduser')\n",
    "\n",
    "    try:\n",
    "        # Tenta acessar o caminho diretamente\n",
    "        client.content(hdfs_folder_path)\n",
    "\n",
    "        print('Os arquivos já estão no Hadoop. Lendo os arquivos.')\n",
    "        df = spark.read.parquet(hdfs_folder_path)\n",
    "    except HdfsError:\n",
    "        print('Colocando no Hadoop.')\n",
    "        if partitionBy:\n",
    "            # Extraindo ano, mês e dia da coluna Date/Time\n",
    "            df = df.withColumn(\"year\", year(\"Date/Time\"))\n",
    "            df = df.withColumn(\"month\", month(\"Date/Time\"))\n",
    "            df = df.withColumn(\"day\", dayofmonth(\"Date/Time\"))\n",
    "            \n",
    "            # Incorporando a lógica de particionamento\n",
    "            df.write.partitionBy(\"year\", \"month\", \"day\").parquet(hdfs_folder_path)\n",
    "            print(f\"Salvo em {hdfs_folder_path} particionado por {partitionBy}\")\n",
    "        else:\n",
    "            df.write.parquet(hdfs_folder_path)\n",
    "            print(f\"Salvo em {hdfs_folder_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Chamando a função spark_hadoop com a lógica de particionamento incorporada\n",
    "df_salvo = spark_hadoop(tweets_pred, folder=\"sentiment\", partitionBy=\"Date/Time\", spark=spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32b7d7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------------------+--------------------+----------+--------+-------+--------------------+----+-----+---+\n",
      "|          Date/Time|    User|               tweet|         clean_tweet|prediction|textblob|  vader|               score|year|month|day|\n",
      "+-------------------+--------+--------------------+--------------------+----------+--------+-------+--------------------+----+-----+---+\n",
      "|2009-05-02 03:08:51|junoaggy|swine flu attacks...|swine flu attacks...|       0.0|     0.0|-0.6047|-0.22676251083612442|2009|    5|  2|\n",
      "|2009-05-02 03:09:26|JasJazzy|Swine Flu  Why oh...|Swine Flu Why oh ...|       0.0|     0.0|-0.3818|-0.14317499846220016|2009|    5|  2|\n",
      "+-------------------+--------+--------------------+--------------------+----------+--------+-------+--------------------+----+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_salvo.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76ae5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
